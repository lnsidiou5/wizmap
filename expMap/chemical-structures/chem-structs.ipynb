{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23b0029e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from os.path import exists, join, basename\n",
    "from tqdm import tqdm\n",
    "from json import load, dump\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "from umap import UMAP\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import importlib.util\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "import time\n",
    "\n",
    "# import local wizmap\n",
    "path = Path.cwd().parent.parent / \"notebook_widget\" / \"wizmap\" / \"wizmap.py\"\n",
    "\n",
    "spec = importlib.util.spec_from_file_location(\"wizmap\", path)\n",
    "wizmap = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(wizmap)\n",
    "\n",
    "load_dotenv(\"../../.env\")\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a1199c",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28db346a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solubility    0\n",
      "Toxicity      0\n",
      "dtype: int64\n",
      "(2000000, 37)\n",
      "(2000000, 4)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "# note that these files are downloaded from https://drive.google.com/drive/folders/1grx1dcYGW--wzrxnrw0d6pwW3fbigWgg\n",
    "# where scaffold.csv is the renamed version of PubChem_2M_10motifs.csv\n",
    "sol_df = pd.read_csv(\"solubility.csv\")\n",
    "tox_df = pd.read_csv(\"toxicity.csv\")\n",
    "df = pd.read_csv(\"scaffold.csv\")\n",
    "# only keep solubility and toxicity\n",
    "sol_df = sol_df[[\"Structure\", \"Solubility\"]]\n",
    "tox_df = tox_df[[\"Structure\", \"Toxicity\"]]\n",
    "\n",
    "# build dict lookups\n",
    "sol_map = dict(zip(sol_df[\"Structure\"].to_numpy(), sol_df[\"Solubility\"].to_numpy()))\n",
    "tox_map = dict(zip(tox_df[\"Structure\"].to_numpy(), tox_df[\"Toxicity\"].to_numpy()))\n",
    "\n",
    "# add columns via dict\n",
    "df[\"Solubility\"] = df[\"Structure\"].map(sol_map)\n",
    "df[\"Toxicity\"]   = df[\"Structure\"].map(tox_map)\n",
    "\n",
    "# verify no duplication or merging errors\n",
    "print(df[[\"Solubility\", \"Toxicity\"]].isna().sum())\n",
    "\n",
    "# create cleaned array and delete unused varibles\n",
    "arr = df.to_numpy()\n",
    "del df, sol_df,tox_df,sol_map,tox_map\n",
    "print(arr.shape)\n",
    "\n",
    "emb = arr[:,0:32]\n",
    "desc = arr[:, 33:]\n",
    "print(desc.shape)\n",
    "del arr\n",
    "\n",
    "out = []\n",
    "n = desc.shape[0]\n",
    "chunk_size = 200000\n",
    "\n",
    "for i in range(0, n, chunk_size):\n",
    "    chunk = desc[i:i+chunk_size, :]\n",
    "\n",
    "    texts = (\n",
    "        chunk[:, 0].astype(str)\n",
    "        + \"; Scaffold: \"   + chunk[:, 1].astype(str)\n",
    "        + \"; Solubility: \" + chunk[:, 2].astype(str)\n",
    "        + \"; Toxicity: \"   + chunk[:, 3].astype(str)\n",
    "    )\n",
    "    out.append(texts)\n",
    "\n",
    "texts_full = np.concatenate(out)\n",
    "del texts, chunk, out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282fdb17",
   "metadata": {},
   "source": [
    "# Dim Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c1a106c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = UMAP(metric=\"cosine\")\n",
    "embeddings_2d = reducer.fit_transform(emb) # 9-10 minutes, 17 min on low power mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c1778d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "del emb # remove emb, since we no longer need it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbf0716",
   "metadata": {},
   "source": [
    "# Wizmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2568dbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = embeddings_2d[:, 0].astype(float).tolist()\n",
    "ys = embeddings_2d[:, 1].astype(float).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1486b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "del embeddings_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "88a21f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start generating multi-level summary batches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000000it [00:15, 130272.10it/s]\n",
      "Level 1/4: 100%|██████████| 13176/13176 [00:02<00:00, 5819.78it/s]\n",
      "Level 2/4: 100%|██████████| 3730/3730 [00:01<00:00, 2411.56it/s]\n",
      "Level 3/4: 100%|██████████| 1137/1137 [00:01<00:00, 937.89it/s] \n",
      "Level 4/4: 100%|██████████| 389/389 [00:00<00:00, 392.02it/s]\n"
     ]
    }
   ],
   "source": [
    "# The following is where the values are computed\n",
    "instructions = \"\"\"You are a computational chemist analyzing chemical structures given as SMILES strings.\n",
    "\n",
    "Analyze these structures to identify:\n",
    "- Structural similarity and shared substructures\n",
    "- Common functional groups present in the SMILES representations\n",
    "- Relevant chemical properties (such as solubility and toxicity)\n",
    "- The chemical rationale for grouping these functional groups together, based on their structural, electronic, and physicochemical characteristics\n",
    "\n",
    "Instead of explaining each structure individually, focus on the patterns that are highly common across the set. \n",
    "Where relevant, include concrete examples of functional groups or substructures inferred from the SMILES strings to illustrate these patterns.\n",
    "\n",
    "Summarize the common patterns in under 50 words, then list 2-5 key descriptors that best characterize the group.\n",
    "\n",
    "Provide your response strictly in the following JSON format:\n",
    "{\n",
    "  \"keywords\": string[], // array of key descriptors that best characterize the group\n",
    "  \"summary\": string // 50 words or fewer summary of the common structural and chemical patterns\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "structure = desc[:,0]\n",
    "model_params = {\n",
    "  \"model\": \"gpt-4o-mini\",\n",
    "  \"temperature\": 0.3\n",
    "}\n",
    "saveDat = wizmap.init_topic_summary_batch(\n",
    "    xs, ys, structure, instructions, \n",
    "    client, \"saves.pkl\", max_zoom_scale=10, batch_name = \"./batches/WM_t-sum\",\n",
    "    send_when_done = False, max_requests_per_batch = 125, openai_model_params=model_params)\n",
    "#grid_dict = wizmap.generate_grid_dict(xs, ys, structure, instructions, client, \"Chemical Structures\", max_zoom_scale=10) # replaced by llm format\n",
    "del structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524c8d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'None': 140}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sending batches: 100%|██████████| 10/10 [00:12<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cycle 1 done\n",
      "{'failed': 8, 'in_progress': 2, 'None': 130}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sending batches: 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cycle 2 done\n",
      "{'failed': 10, 'completed': 2, 'None': 128}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sending batches: 100%|██████████| 10/10 [00:14<00:00,  1.41s/it]\n"
     ]
    }
   ],
   "source": [
    "# can remove this if you set, and can send all at once send_when_done = True\n",
    "saveDat = wizmap.BatchFileTracker(\"saves.pkl\")\n",
    "saveDat.resend_until_done(client, sleep_time=120, batches_per_send = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a64ed67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wizmap-topic-summaries_43.jsonl failed\n",
      "Errors(data=[BatchError(code='token_limit_exceeded', line=None, message='Enqueued token limit reached for gpt-4o-mini in organization org-snxFEOUudfOLSycGh385r02G. Limit: 2,000,000 enqueued tokens. Please try again once some in_progress batches have been completed.', param=None)], object='list')\n",
      "wizmap-topic-summaries_49.jsonl failed\n",
      "Errors(data=[BatchError(code='token_limit_exceeded', line=None, message='Enqueued token limit reached for gpt-4o-mini in organization org-snxFEOUudfOLSycGh385r02G. Limit: 2,000,000 enqueued tokens. Please try again once some in_progress batches have been completed.', param=None)], object='list')\n",
      "wizmap-topic-summaries_50.jsonl failed\n",
      "Errors(data=[BatchError(code='token_limit_exceeded', line=None, message='Enqueued token limit reached for gpt-4o-mini in organization org-snxFEOUudfOLSycGh385r02G. Limit: 2,000,000 enqueued tokens. Please try again once some in_progress batches have been completed.', param=None)], object='list')\n",
      "wizmap-topic-summaries_51.jsonl failed\n",
      "Errors(data=[BatchError(code='token_limit_exceeded', line=None, message='Enqueued token limit reached for gpt-4o-mini in organization org-snxFEOUudfOLSycGh385r02G. Limit: 2,000,000 enqueued tokens. Please try again once some in_progress batches have been completed.', param=None)], object='list')\n",
      "wizmap-topic-summaries_52.jsonl failed\n",
      "Errors(data=[BatchError(code='token_limit_exceeded', line=None, message='Enqueued token limit reached for gpt-4o-mini in organization org-snxFEOUudfOLSycGh385r02G. Limit: 2,000,000 enqueued tokens. Please try again once some in_progress batches have been completed.', param=None)], object='list')\n",
      "wizmap-topic-summaries_53.jsonl failed\n",
      "Errors(data=[BatchError(code='token_limit_exceeded', line=None, message='Enqueued token limit reached for gpt-4o-mini in organization org-snxFEOUudfOLSycGh385r02G. Limit: 2,000,000 enqueued tokens. Please try again once some in_progress batches have been completed.', param=None)], object='list')\n",
      "wizmap-topic-summaries_54.jsonl failed\n",
      "Errors(data=[BatchError(code='token_limit_exceeded', line=None, message='Enqueued token limit reached for gpt-4o-mini in organization org-snxFEOUudfOLSycGh385r02G. Limit: 2,000,000 enqueued tokens. Please try again once some in_progress batches have been completed.', param=None)], object='list')\n",
      "wizmap-topic-summaries_55.jsonl failed\n",
      "Errors(data=[BatchError(code='token_limit_exceeded', line=None, message='Enqueued token limit reached for gpt-4o-mini in organization org-snxFEOUudfOLSycGh385r02G. Limit: 2,000,000 enqueued tokens. Please try again once some in_progress batches have been completed.', param=None)], object='list')\n",
      "wizmap-topic-summaries_58.jsonl failed\n",
      "Errors(data=[BatchError(code='token_limit_exceeded', line=None, message='Enqueued token limit reached for gpt-4o-mini in organization org-snxFEOUudfOLSycGh385r02G. Limit: 2,000,000 enqueued tokens. Please try again once some in_progress batches have been completed.', param=None)], object='list')\n",
      "wizmap-topic-summaries_59.jsonl failed\n",
      "Errors(data=[BatchError(code='token_limit_exceeded', line=None, message='Enqueued token limit reached for gpt-4o-mini in organization org-snxFEOUudfOLSycGh385r02G. Limit: 2,000,000 enqueued tokens. Please try again once some in_progress batches have been completed.', param=None)], object='list')\n",
      "wizmap-topic-summaries_60.jsonl failed\n",
      "Errors(data=[BatchError(code='token_limit_exceeded', line=None, message='Enqueued token limit reached for gpt-4o-mini in organization org-snxFEOUudfOLSycGh385r02G. Limit: 2,000,000 enqueued tokens. Please try again once some in_progress batches have been completed.', param=None)], object='list')\n",
      "wizmap-topic-summaries_61.jsonl failed\n",
      "Errors(data=[BatchError(code='token_limit_exceeded', line=None, message='Enqueued token limit reached for gpt-4o-mini in organization org-snxFEOUudfOLSycGh385r02G. Limit: 2,000,000 enqueued tokens. Please try again once some in_progress batches have been completed.', param=None)], object='list')\n",
      "wizmap-topic-summaries_64.jsonl failed\n",
      "Errors(data=[BatchError(code='token_limit_exceeded', line=None, message='Enqueued token limit reached for gpt-4o-mini in organization org-snxFEOUudfOLSycGh385r02G. Limit: 2,000,000 enqueued tokens. Please try again once some in_progress batches have been completed.', param=None)], object='list')\n",
      "wizmap-topic-summaries_65.jsonl failed\n",
      "Errors(data=[BatchError(code='token_limit_exceeded', line=None, message='Enqueued token limit reached for gpt-4o-mini in organization org-snxFEOUudfOLSycGh385r02G. Limit: 2,000,000 enqueued tokens. Please try again once some in_progress batches have been completed.', param=None)], object='list')\n",
      "wizmap-topic-summaries_66.jsonl failed\n",
      "Errors(data=[BatchError(code='token_limit_exceeded', line=None, message='Enqueued token limit reached for gpt-4o-mini in organization org-snxFEOUudfOLSycGh385r02G. Limit: 2,000,000 enqueued tokens. Please try again once some in_progress batches have been completed.', param=None)], object='list')\n",
      "wizmap-topic-summaries_67.jsonl failed\n",
      "Errors(data=[BatchError(code='token_limit_exceeded', line=None, message='Enqueued token limit reached for gpt-4o-mini in organization org-snxFEOUudfOLSycGh385r02G. Limit: 2,000,000 enqueued tokens. Please try again once some in_progress batches have been completed.', param=None)], object='list')\n",
      "wizmap-topic-summaries_68.jsonl failed\n",
      "Errors(data=[BatchError(code='token_limit_exceeded', line=None, message='Enqueued token limit reached for gpt-4o-mini in organization org-snxFEOUudfOLSycGh385r02G. Limit: 2,000,000 enqueued tokens. Please try again once some in_progress batches have been completed.', param=None)], object='list')\n",
      "wizmap-topic-summaries_69.jsonl failed\n",
      "Errors(data=[BatchError(code='token_limit_exceeded', line=None, message='Enqueued token limit reached for gpt-4o-mini in organization org-snxFEOUudfOLSycGh385r02G. Limit: 2,000,000 enqueued tokens. Please try again once some in_progress batches have been completed.', param=None)], object='list')\n",
      "{'completed': 52, 'failed': 18}\n"
     ]
    }
   ],
   "source": [
    "# check completion\n",
    "saveDat = wizmap.BatchFileTracker(\"saves.pkl\")\n",
    "if saveDat.checkCompletion(client, verbose=True):\n",
    "    saveDat.download_batch_outputs(client)\n",
    "    print(\"All done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f22e49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_dict = wizmap.generate_batch_grid_dict(client, embedding_name=\"Chemical Structures\", savefile=\"saves.pkl\", retrieve_batches = False)\n",
    "#Create Datalist, may need to rerun section for texts_full if this isn't done continuously\n",
    "data_list = wizmap.generate_data_list(saveDat.xs, saveDat.ys, texts_full)\n",
    "del texts_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007c6a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "wizmap.save_json_files(data_list, grid_dict, output_dir=\"./\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wizmap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
