{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a1f3d0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from os.path import exists, join, basename\n",
    "from tqdm import tqdm\n",
    "from json import load, dump\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "from umap import UMAP\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import importlib.util\n",
    "from pathlib import Path\n",
    "\n",
    "# import local wizmap\n",
    "path = Path.cwd().parent / \"notebook_widget\" / \"wizmap\" / \"wizmap.py\"\n",
    "\n",
    "spec = importlib.util.spec_from_file_location(\"wizmap\", path)\n",
    "wizmap = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(wizmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d1eb60",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a88f5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "with open(\"train.json\", \"r\") as f:\n",
    "    texts = load(f)\n",
    "texts_arr = np.array([texts[f\"{i}\"] for i in range(len(texts))])\n",
    "embs = np.loadtxt(\"12.txt\")\n",
    "\n",
    "# Lists to store each part\n",
    "array_indices = []\n",
    "word_indices = []\n",
    "words = []\n",
    "categories = []\n",
    "\n",
    "# Open and parse the file\n",
    "with open(\"train.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()  # remove newline\n",
    "        if not line:\n",
    "            continue  # skip empty lines\n",
    "        \n",
    "        # Split at ':' to separate indices from word+category\n",
    "        indices_part, rest = line.split(\":\", 1)\n",
    "        \n",
    "        # Remove parentheses and split indices\n",
    "        array_idx, word_idx = indices_part.strip(\"()\").split(\",\")\n",
    "        array_idx = int(array_idx)\n",
    "        word_idx = int(word_idx) - 1\n",
    "        \n",
    "        # Split word and category by whitespace\n",
    "        word, category = rest.strip().split()\n",
    "        \n",
    "        # Append to lists\n",
    "        array_indices.append(array_idx)\n",
    "        word_indices.append(word_idx)\n",
    "        words.append(word)\n",
    "        categories.append(category)\n",
    "\n",
    "# Optional: convert indices to numpy arrays\n",
    "array_indices = np.array(array_indices)\n",
    "word_indices = np.array(word_indices)\n",
    "words = np.array(words)\n",
    "categories = np.array(categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a525cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check\n",
    "print(embs.shape)\n",
    "print(texts_arr.shape)\n",
    "#print(text_arr[0:4])\n",
    "# print(array_indices[:5])\n",
    "# print(word_indices[:5])\n",
    "# print(words[:5])\n",
    "# print(categories[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f4cd13",
   "metadata": {},
   "source": [
    "# Dim Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d49d91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = UMAP(metric=\"cosine\")\n",
    "embeddings_2d = reducer.fit_transform(embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08847e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.title(f\"UMAP Projected Embeddings of {embs.shape[0]} Texts\")\n",
    "# plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], s=0.1, alpha=0.2)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9ee8d9",
   "metadata": {},
   "source": [
    "# Wizmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3045e9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = embeddings_2d[:, 0].astype(float).tolist()\n",
    "ys = embeddings_2d[:, 1].astype(float).tolist()\n",
    "\n",
    "# set texts with bracket around focus word\n",
    "temp_texts = []\n",
    "\n",
    "for text_i, word, idx in zip(array_indices, words, word_indices):\n",
    "    tokens = texts_arr[text_i].split()\n",
    "\n",
    "    # Safety check\n",
    "    if 0 <= idx < len(tokens) and tokens[idx] == word:\n",
    "        tokens[idx] = f\"[{tokens[idx]}]\"\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Mismatch at index {idx}: expected '{word}', found '{tokens[idx] if idx < len(tokens) else None}'\"\n",
    "        )\n",
    "\n",
    "    temp_texts.append(\" \".join(tokens))\n",
    "\n",
    "texts = np.array(temp_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af681b2",
   "metadata": {},
   "source": [
    "## Grid dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1cfdba37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start generating data list...\n",
      "Start generating contours...\n",
      "Start generating multi-level summaries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4284it [00:00, 196200.11it/s]\n",
      " 67%|██████▋   | 4/6 [00:00<00:00, 36.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 1\n",
      "200 2\n",
      "300 1\n",
      "400 1\n",
      "500 3\n",
      "600 1\n",
      "700 1\n",
      "800 2\n",
      "900 1\n",
      "1000 3\n",
      "1100 1\n",
      "1200 1\n",
      "1300 2\n",
      "1400 1\n",
      "1500 1\n",
      "1600 1\n",
      "1700 6\n",
      "1800 2\n",
      "1900 2\n",
      "2000 1\n",
      "2100 3\n",
      "2200 1\n",
      "2300 2\n",
      "2400 1\n",
      "2500 4\n",
      "2600 1\n",
      "2700 2\n",
      "2800 3\n",
      "2900 3\n",
      "2900 1\n",
      "2900 1\n",
      "2900 1\n",
      "2900 1\n",
      "2900 1\n",
      "2900 1\n",
      "2900 1\n",
      "2900 1\n",
      "2900 1\n",
      "2900 2\n",
      "3000 4\n",
      "3000 1\n",
      "3000 1\n",
      "3000 1\n",
      "3000 1\n",
      "3100 3\n",
      "3100 2\n",
      "3200 6\n",
      "3300 6\n",
      "3300 1\n",
      "3400 5\n",
      "3500 7\n",
      "3600 7\n",
      "3600 3\n",
      "3700 12\n",
      "3700 21\n",
      "3800 6\n",
      "3800 1\n",
      "3800 2\n",
      "3900 15\n",
      "4000 9\n",
      "4100 15\n",
      "4100 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 46.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_list = wizmap.generate_data_list(xs, ys, texts)\n",
    "# The following is where the values are computed\n",
    "grid_dict = wizmap.generate_grid_dict(xs, ys, texts, \"Word Contexts\") # replaced by llm format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faed75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wizmap.save_json_files(data_list, grid_dict, output_dir=\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "22bb3d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = (\n",
    "    \"https://raw.githubusercontent.com/lnsidiou5/wizmap/refs/heads/main/expMap/data.ndjson\"\n",
    ")\n",
    "grid_url = (\n",
    "    \"https://raw.githubusercontent.com/lnsidiou5/wizmap/refs/heads/main/expMap/grid.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249aab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display wizmaps\n",
    "wizmap.visualize(data_url = data_url, grid_url = grid_url, height=700)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wizmap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
