{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f3d0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from os.path import exists, join, basename\n",
    "from tqdm import tqdm\n",
    "from json import load, dump\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from quadtreed3 import Quadtree, Node\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from scipy.stats import norm\n",
    "from typing import Tuple\n",
    "from io import BytesIO\n",
    "from umap import UMAP\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ndjson\n",
    "import requests\n",
    "import urllib\n",
    "import wizmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d1eb60",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a88f5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "with open(\"train.json\", \"r\") as f:\n",
    "    texts = load(f)\n",
    "texts_arr = np.array([texts[f\"{i}\"] for i in range(len(texts))])\n",
    "embs = np.loadtxt(\"12.txt\")\n",
    "\n",
    "# Lists to store each part\n",
    "array_indices = []\n",
    "word_indices = []\n",
    "words = []\n",
    "categories = []\n",
    "\n",
    "# Open and parse the file\n",
    "with open(\"train.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()  # remove newline\n",
    "        if not line:\n",
    "            continue  # skip empty lines\n",
    "        \n",
    "        # Split at ':' to separate indices from word+category\n",
    "        indices_part, rest = line.split(\":\", 1)\n",
    "        \n",
    "        # Remove parentheses and split indices\n",
    "        array_idx, word_idx = indices_part.strip(\"()\").split(\",\")\n",
    "        array_idx = int(array_idx)\n",
    "        word_idx = int(word_idx) - 1\n",
    "        \n",
    "        # Split word and category by whitespace\n",
    "        word, category = rest.strip().split()\n",
    "        \n",
    "        # Append to lists\n",
    "        array_indices.append(array_idx)\n",
    "        word_indices.append(word_idx)\n",
    "        words.append(word)\n",
    "        categories.append(category)\n",
    "\n",
    "# Optional: convert indices to numpy arrays\n",
    "array_indices = np.array(array_indices)\n",
    "word_indices = np.array(word_indices)\n",
    "words = np.array(words)\n",
    "categories = np.array(categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a525cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check\n",
    "print(embs.shape)\n",
    "print(texts_arr.shape)\n",
    "#print(text_arr[0:4])\n",
    "# print(array_indices[:5])\n",
    "# print(word_indices[:5])\n",
    "# print(words[:5])\n",
    "# print(categories[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f4cd13",
   "metadata": {},
   "source": [
    "# Dim Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d49d91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = UMAP(metric=\"cosine\")\n",
    "embeddings_2d = reducer.fit_transform(embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08847e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.title(f\"UMAP Projected Embeddings of {embs.shape[0]} Texts\")\n",
    "# plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], s=0.1, alpha=0.2)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9ee8d9",
   "metadata": {},
   "source": [
    "# Wizmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3045e9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = embeddings_2d[:, 0].astype(float).tolist()\n",
    "ys = embeddings_2d[:, 1].astype(float).tolist()\n",
    "texts = np.array([\n",
    "    f\"[{words[i]},{word_indices[i]}]: {texts_arr[array_indices[i]]}\" for i in range(len(array_indices))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfdba37",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = wizmap.generate_data_list(xs, ys, texts)\n",
    "# The following is where the values are computed\n",
    "grid_dict = wizmap.generate_grid_dict(xs, ys, texts, \"Word Contexts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faed75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wizmap.save_json_files(data_list, grid_dict, output_dir=\"./\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ecbded",
   "metadata": {},
   "source": [
    "Hosting Wizmap Files using `python -m http.server 8000`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bb3d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = (\n",
    "    \"https://raw.githubusercontent.com/lnsidiou5/wizmap/refs/heads/main/expMap/data.ndjson\"\n",
    ")\n",
    "grid_url = (\n",
    "    \"https://raw.githubusercontent.com/lnsidiou5/wizmap/refs/heads/main/expMap/grid.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249aab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display wizmaps\n",
    "wizmap.visualize(data_url = data_url, grid_url = grid_url, height=700)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wizmap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
